{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAdNVCRCaOX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "023fdbef-2a17-4533-ae12-654c0066c712"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgbCnRhLaGh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/gdrive/My Drive/Sentihood')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzW9e-RG7svF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQAurcTBaUzy",
        "colab_type": "text"
      },
      "source": [
        "# Approach\n",
        "\n",
        "The Sentihood dataset has for each text, some targets (namely LOCATION1 and LOCATION2) and for each target has an aspect and its corresponding sentiment. Due to the association of a target with multiple aspects, it would not be beneficial to build a model which predicts a single aspect and sentiment for a given text and target pair.\n",
        "\n",
        "Hence, I designed a model which will perform multi-label classification for the aspect and for each aspect predict 3 classes of sentiment(None being the extra class which represents that the aspect is not appropiate for the target).\n",
        "\n",
        "The model will take the text and target as input and predict probabilities for all possible aspects (i.e. 12 values) and probabilities for all possible sentiments for all possible aspects (i.e. 12*3=36 values). The experiments have been done using _bert-base-uncased_ and _roberta_ as the main component of the models and the hidden states of the first token are used to output the logits. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ8pBrW3b_oK",
        "colab_type": "text"
      },
      "source": [
        "# How to use the missing data?\n",
        "\n",
        "The Sentihood dataset also has some missing values. Inorder to use the unlabelled data as well, I took the help of a semi-supervised learning concept, Pseudo-Labelling. The missing data of the train and dev sets are used for pseudo-labelling. The test set is avoided so as to prevent any leakage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfWFbiCclxgh",
        "colab_type": "text"
      },
      "source": [
        "# Results Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1bbbPJn7xkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze(file_name):\n",
        "  df = pd.read_csv(file_name)\n",
        "\n",
        "  aspect, sentiment = {}, {}\n",
        "  c_aspect, c_sentiment = {}, {}\n",
        "\n",
        "\n",
        "  for i, r in df.iterrows():\n",
        "    a_l = str(r['aspect']).split(' ')\n",
        "    s_l = str(r['sentiment']).split(' ')\n",
        "    a_p = str(r['pred_aspect']).split(' ')\n",
        "    s_p = str(r['pred_sentiment']).split(' ')\n",
        "\n",
        "    for i,j in zip(a_l, a_p):\n",
        "      if i not in aspect.keys():\n",
        "        aspect[i] = 0\n",
        "        c_aspect[i] = 0\n",
        "      aspect[i]+=1\n",
        "      if i==j:\n",
        "        c_aspect[i]+=1\n",
        "\n",
        "    for k, i, j in zip(a_l, s_l, s_p):\n",
        "      if i not in sentiment.keys():\n",
        "        sentiment[i] = 0\n",
        "        c_sentiment[i] = 0\n",
        "      sentiment[i]+=1\n",
        "      if i==j:\n",
        "        c_sentiment[i]+=1\n",
        "  \n",
        "  print('Aspect/Sentiment wise accuracy')\n",
        "  print('----------------------------Aspect----------------------------')\n",
        "  for k,v in aspect.items():\n",
        "    print(f'{k} --> {c_aspect[k]/v}')\n",
        "  print()\n",
        "  print('----------------------------Sentiment----------------------------')\n",
        "  for k,v in sentiment.items():\n",
        "    print(f'{k} --> {c_sentiment[k]/v}')\n",
        "  print()\n",
        "  print('----------------------------Aspect wise Sentiment----------------------------')\n",
        "  for k, v in aspect.items():\n",
        "    tpos, tneg, pos, neg = 0, 0, 0, 0\n",
        "    for _, r in df.iterrows():\n",
        "      a_l = str(r['aspect']).split(' ')\n",
        "      s_l = str(r['sentiment']).split(' ')\n",
        "      s_p = str(r['pred_sentiment']).split(' ')\n",
        "\n",
        "      for i, a in enumerate(a_l):\n",
        "        if a==k:\n",
        "          if s_l[i]=='Positive':\n",
        "            tpos+=1\n",
        "            if i<len(s_p) and s_l[i]==s_p[i]:\n",
        "              pos+=1\n",
        "          if s_l[i]=='Negative':\n",
        "            tneg+=1\n",
        "            if i<len(s_p) and s_l[i]==s_p[i]:\n",
        "              neg+=1\n",
        "    ppos = pos/tpos if tpos!=0 and pos!=0 else f'{pos}/{tpos}'\n",
        "    pneg = neg/tneg if tneg!=0 and neg!=0 else f'{neg}/{tneg}'\n",
        "    \n",
        "    print(f'Aspect : {k} | Postive: {ppos} | Negative: {pneg}') "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqgAibzYd6rC",
        "colab_type": "text"
      },
      "source": [
        "## BERT BASE MODEL RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "103vdB3obYHd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "5eb16bfa-365a-47a6-e3ac-51313f8f6a39"
      },
      "source": [
        "analyze(os.path.join('run_bert_multi_20', 'sub.csv'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect/Sentiment wise accuracy\n",
            "----------------------------Aspect----------------------------\n",
            "safety --> 0.7785234899328859\n",
            "general --> 0.8460176991150442\n",
            "price --> 0.6609442060085837\n",
            "live --> 0.6145833333333334\n",
            "transit-location --> 0.6502463054187192\n",
            "quiet --> 0.4583333333333333\n",
            "shopping --> 0.6973684210526315\n",
            "dining --> 0.6\n",
            "nightlife --> 0.676056338028169\n",
            "multicultural --> 0.7708333333333334\n",
            "green-nature --> 0.6136363636363636\n",
            "touristy --> 0.6666666666666666\n",
            "\n",
            "----------------------------Sentiment----------------------------\n",
            "Positive --> 0.9306759098786829\n",
            "Negative --> 0.709832134292566\n",
            "\n",
            "----------------------------Aspect wise Sentiment----------------------------\n",
            "Aspect : safety | Postive: 0.92 | Negative: 0.7469879518072289\n",
            "Aspect : general | Postive: 0.8819599109131403 | Negative: 0.8129496402877698\n",
            "Aspect : price | Postive: 0.7685185185185185 | Negative: 0.6153846153846154\n",
            "Aspect : live | Postive: 0.8333333333333334 | Negative: 0.5925925925925926\n",
            "Aspect : transit-location | Postive: 0.8888888888888888 | Negative: 0.36585365853658536\n",
            "Aspect : quiet | Postive: 0.875 | Negative: 0.05\n",
            "Aspect : shopping | Postive: 0.974025974025974 | Negative: 0/1\n",
            "Aspect : dining | Postive: 0.9428571428571428 | Negative: 0/2\n",
            "Aspect : nightlife | Postive: 0.9066666666666666 | Negative: 0/2\n",
            "Aspect : multicultural | Postive: 0.9148936170212766 | Negative: 0.25\n",
            "Aspect : green-nature | Postive: 0.9148936170212766 | Negative: 0/0\n",
            "Aspect : touristy | Postive: 0.8333333333333334 | Negative: 0/0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHbP5LgceBiY",
        "colab_type": "text"
      },
      "source": [
        "## BERT MODEL + PSEUDO-LABELLING RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkKlU9kkBxt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "5426ec9e-53d1-4b7f-cf7b-4af60f934f33"
      },
      "source": [
        "analyze(os.path.join('run_bert_multi_pseudo', 'sub.csv'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect/Sentiment wise accuracy\n",
            "----------------------------Aspect----------------------------\n",
            "safety --> 0.7635135135135135\n",
            "general --> 0.8253119429590018\n",
            "price --> 0.6331877729257642\n",
            "live --> 0.65625\n",
            "transit-location --> 0.6548223350253807\n",
            "quiet --> 0.4782608695652174\n",
            "shopping --> 0.76\n",
            "dining --> 0.6363636363636364\n",
            "nightlife --> 0.7101449275362319\n",
            "multicultural --> 0.723404255319149\n",
            "green-nature --> 0.627906976744186\n",
            "touristy --> 0.72\n",
            "\n",
            "----------------------------Sentiment----------------------------\n",
            "Positive --> 0.9241622574955908\n",
            "Negative --> 0.6771844660194175\n",
            "\n",
            "----------------------------Aspect wise Sentiment----------------------------\n",
            "Aspect : safety | Postive: 0.88 | Negative: 0.7469879518072289\n",
            "Aspect : general | Postive: 0.8663697104677061 | Negative: 0.7913669064748201\n",
            "Aspect : price | Postive: 0.7777777777777778 | Negative: 0.5874125874125874\n",
            "Aspect : live | Postive: 0.8333333333333334 | Negative: 0.2962962962962963\n",
            "Aspect : transit-location | Postive: 0.8611111111111112 | Negative: 0.34146341463414637\n",
            "Aspect : quiet | Postive: 0.6875 | Negative: 0.05\n",
            "Aspect : shopping | Postive: 0.961038961038961 | Negative: 0/1\n",
            "Aspect : dining | Postive: 0.8857142857142857 | Negative: 0/2\n",
            "Aspect : nightlife | Postive: 0.88 | Negative: 0/2\n",
            "Aspect : multicultural | Postive: 0.8723404255319149 | Negative: 0/4\n",
            "Aspect : green-nature | Postive: 0.9148936170212766 | Negative: 0/0\n",
            "Aspect : touristy | Postive: 0.7666666666666667 | Negative: 0/0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhW3aw4FjBQW",
        "colab_type": "text"
      },
      "source": [
        "BERT based models are quite accurate in predicting aspects like \"general\", \"safety\" and \"multicultural\". They perform a bit poorly on aspects like \"quiet\", \"green-nature\" and \"price\". Although pseudo-labelling is not improving the results, its results are also similar. Analysing the aspect wise sentiment prediction, the models perform well on the Positive class for almost all aspects. However, the performance of Negative sentiment is poor due to the class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbj7Y2dKDVmx",
        "colab_type": "text"
      },
      "source": [
        "## ROBERTA BASE MODEL RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnb1i5jhDUpX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "773b6014-f442-4b97-eabd-644964422761"
      },
      "source": [
        "analyze(os.path.join('run_roberta_multi_20', 'sub.csv'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect/Sentiment wise accuracy\n",
            "----------------------------Aspect----------------------------\n",
            "safety --> 0.7872340425531915\n",
            "general --> 0.8405017921146953\n",
            "price --> 0.6454545454545455\n",
            "live --> 0.5789473684210527\n",
            "transit-location --> 0.6403940886699507\n",
            "quiet --> 0.5\n",
            "shopping --> 0.7397260273972602\n",
            "dining --> 0.6060606060606061\n",
            "nightlife --> 0.6617647058823529\n",
            "multicultural --> 0.7755102040816326\n",
            "green-nature --> 0.6585365853658537\n",
            "touristy --> 0.6086956521739131\n",
            "\n",
            "----------------------------Sentiment----------------------------\n",
            "Positive --> 0.9225289403383793\n",
            "Negative --> 0.683046683046683\n",
            "\n",
            "----------------------------Aspect wise Sentiment----------------------------\n",
            "Aspect : safety | Postive: 0.8533333333333334 | Negative: 0.7228915662650602\n",
            "Aspect : general | Postive: 0.8752783964365256 | Negative: 0.7410071942446043\n",
            "Aspect : price | Postive: 0.6944444444444444 | Negative: 0.5804195804195804\n",
            "Aspect : live | Postive: 0.8205128205128205 | Negative: 0.48148148148148145\n",
            "Aspect : transit-location | Postive: 0.8777777777777778 | Negative: 0.3902439024390244\n",
            "Aspect : quiet | Postive: 0.6875 | Negative: 0.1\n",
            "Aspect : shopping | Postive: 0.935064935064935 | Negative: 0/1\n",
            "Aspect : dining | Postive: 0.8857142857142857 | Negative: 0/2\n",
            "Aspect : nightlife | Postive: 0.8666666666666667 | Negative: 0/2\n",
            "Aspect : multicultural | Postive: 0.9148936170212766 | Negative: 0.25\n",
            "Aspect : green-nature | Postive: 0.8297872340425532 | Negative: 0/0\n",
            "Aspect : touristy | Postive: 0.7 | Negative: 0/0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTkberwojiVf",
        "colab_type": "text"
      },
      "source": [
        "## ROBERTA MODEL + PSEUDO-LABELLING RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r-28axjjow4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "e91c2c43-4319-4e2f-bbfb-2ce527f505ea"
      },
      "source": [
        "analyze(os.path.join('run_roberta_multi_pseudo_20', 'sub.csv'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect/Sentiment wise accuracy\n",
            "----------------------------Aspect----------------------------\n",
            "safety --> 0.7777777777777778\n",
            "general --> 0.8375451263537906\n",
            "price --> 0.6858407079646017\n",
            "live --> 0.5894736842105263\n",
            "transit-location --> 0.64\n",
            "shopping --> 0.7432432432432432\n",
            "dining --> 0.6363636363636364\n",
            "quiet --> 0.45454545454545453\n",
            "nightlife --> 0.7611940298507462\n",
            "multicultural --> 0.7755102040816326\n",
            "green-nature --> 0.6410256410256411\n",
            "touristy --> 0.68\n",
            "\n",
            "----------------------------Sentiment----------------------------\n",
            "Positive --> 0.9126559714795008\n",
            "Negative --> 0.7241379310344828\n",
            "\n",
            "----------------------------Aspect wise Sentiment----------------------------\n",
            "Aspect : safety | Postive: 0.7866666666666666 | Negative: 0.7590361445783133\n",
            "Aspect : general | Postive: 0.8596881959910914 | Negative: 0.7913669064748201\n",
            "Aspect : price | Postive: 0.75 | Negative: 0.6573426573426573\n",
            "Aspect : live | Postive: 0.8076923076923077 | Negative: 0.37037037037037035\n",
            "Aspect : transit-location | Postive: 0.8555555555555555 | Negative: 0.3902439024390244\n",
            "Aspect : shopping | Postive: 0.935064935064935 | Negative: 0/1\n",
            "Aspect : dining | Postive: 0.8857142857142857 | Negative: 0/2\n",
            "Aspect : quiet | Postive: 0.6875 | Negative: 0.05\n",
            "Aspect : nightlife | Postive: 0.8533333333333334 | Negative: 0/2\n",
            "Aspect : multicultural | Postive: 0.8723404255319149 | Negative: 0/4\n",
            "Aspect : green-nature | Postive: 0.8297872340425532 | Negative: 0/0\n",
            "Aspect : touristy | Postive: 0.7666666666666667 | Negative: 0/0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrvP6qJljpNj",
        "colab_type": "text"
      },
      "source": [
        "Roberta based models perform a little better than BERT as per metrics like F1 score and AUC-ROC score, specifically on Sentiment. They perform well on aspects like \"general\", \"safety\" and multiculture and a bit poorly on \"quiet\", \"live\" and \"dining\". When analysing the aspect wise sentiment predictions, it is observed that Roberta models perform a little better on the Negative class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmDZtBz9eVSf",
        "colab_type": "text"
      },
      "source": [
        "## Grammar Evaluation\n",
        "\n",
        "Despite the availability of many machine learning libraries, my favourite library is __pytorch__, since it gives complete control of the ML pipeline. Moreover, the discussion forum of pytorch is also very active and helpful. There is no doubt why the number of Github repositories with pytorch code is on the rise. The only point that I dislike is that one has to put much effort while working with pytorch. One will have full control of the code, but \"with great power comes great responsibility.\" Hence, one must be very careful while working with pytorch, paying attention to all the minute details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0XOjTSNCrVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gLf6j3IeTyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}